### 创建一个线程
创建线程一般用 threading 类来创建线程，thread 模块被废弃，python3中的thread
模块为_thread, 下面的代码可以看到不用等待，直接执行，相当于并行执行了
可以提高速度
    
        import time
        import threading
        def work():
        for i in range(3):
            print("---->",i)
            time.selloleep(1)
        
        work()
        t = Thread(target=work)
        t.start()
        
        t2 = Thread(target=work)
        t2.start()
        
        t3 = Thread(target=work)
        t3.start()
        
        t4 = Thread(target=work)
        t4.start()
### 继承实现
可以直接继承threading.Thread继承一个新子类，然后实力花后调用start(),方法
运行run()
    
        from threading import Thread
        import time
        class MyThread(Thread):
            def run(self):
                for i in range(3):
                    time.sleep(1)
                    print(f'name{i}')
            
        def test():
            t = MyThread()
            t.start()
            t2 = MyThread()
            t2.start()
        
        test()
### 同步

对于以上的线程，不对线程加以控制，线程的推进顺序是不可预料的，那么需要对
线程加以控制，使用Thread对象的Lock 和 Rlock 实现简单的线程同步，
多线程的优势是可以同时运行多个任务，当线程需要共享数据时，存在数据不同步
的问题, 加锁后会保证多线程修改不会出错
        
        import threading
        import time
        
         g_num = 0
        
         def test1(num):
            global g_num
            for i in range(num):
                mutex.acquire()  # 上锁
                g_num += 1
                mutex.release()  # 解锁
        
            print("---test1---g_num=%d"%g_num)
         
        # 创建一个互斥锁
        # 默认是未上锁的状态
        mutex = threading.Lock()
        
        # 创建2个线程，让他们各自对g_num加1000000次
        p1 = threading.Thread(target=test1, args=(1000000,))
        p1.start()
        
        p2 = threading.Thread(target=test2, args=(1000000,))
        p2.start()
### 死锁
python 中在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时
等待对方的资源就会产生死锁，比如在一个两个账户相互转钱，
    
        import time
        import threading
        class Account:
            def __init__(self,_id, balance, lock):
                self.id = _id
                self.balance = balance
                self.lock = lock
        
            def withdraw(self, amount):
                self.balance -= amount
        
            def deposit(self, amount):
                self.balance += amount
        
        def transfer(_from, to, amount):
            if _from.lock.acquire():
                _from.withdraw(amount)
                time.sleep(1)
                print('wait for lock')
                if to.lock.acquire():
                    to.deposit(amount)
                    to.lock.release()
                _from.lock.release()
            print('finish...')
        
        a = Account('a', 1000, threading.Lock())
        b = Account('b', 1000, threading.Lock())
        threading.Thread(target = transfer, args = (a, b, 100)).start()
        threading.Thread(target = transfer, args = (b, a, 200)).start()
                        
下面的程序就是线程同时获取多个资源而造成的死锁
由于两个线程获取锁的顺序是相反的,对于互斥资源`lock1`,和`lock2`
如果是正常推进，线程1得到`lock1`,`lock2` 执行完成后，释放资源
线程2 在去执行，这样是没有问题的，但是
在线程1 的到`lock1`时有一点延迟，导致线程2 的到了 `lock2`,那么线程1 无法继续
线程2同样因为`lock1`的阻塞而无法执行，这就是由于同时获取多个资源产生了死锁的过程

    import threading
    import time
    lock1 = threading.Lock()
    lock2 = threading.Lock()
    
    def thread1():

    with lock1:
        print('-----get lock1 ----')
        # time.sleep(0.1)
        with lock2:
            print('-----get lock2----')

    def thread2():
        with lock2:
            print('-----get lock2----')
            with lock1:
                print('-----get lock1----')
    
    t1 = threading.Thread(target=thread1)
    t2 = threading.Thread(target=thread2)
    t1.start()
    t2.start()
1. 解决方法是设置等待时间，如果超过等待时间就释放资源，
2. 给每一个锁分配一个唯一的id，然后只允许按照升序规则来使用多个锁，--- `python cookbook`
3. 编写代码时逻辑要正确



### 操作系统中的死锁
死锁是指多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。
死锁是指多个进程因为竞争资源而造成的一种僵局（相互等待）,若无外力作用，这些进程都将无法向前推进
对于两个线程，他们的执行都需要资源A， 和资源B，如果他们同时分别得到了资源A，资源B，那么此时两个线程
都无法执行，都在等待对方资源释放，从而造成了死锁
### 产生死锁的原因
1. 竞争资源（竞争临界资源）
2. 进程间的推进顺序不当（银行家算法）
### 产生死锁的必要条件
1. 互斥条件
2. 请求与保持
3. 不剥夺
4. 环路等待
所以产生死锁还是比较困难的，但一旦产生就很危险



### 进程(Process)
进程的创建过程和线程类似 进程包是 `multiprocessing` 
创建一个进程
    
    from multiprocessing import Process
    import time
    import os
    def boo():
        for i in range(3):
            print(f'{i}---',os.getpid())
            time.sleep(1)
    
    
    
    p1 = Process(target=boo)
    p1.start()
    p2 = Process(target=boo)
    p2.start()

### 进程之间不共享全局变量
    
    from multiprocessing import Process
    import os
    import time
    
    nums = [11, 22]
    
    def work1():
        """子进程要执行的代码"""
        print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums))
        for i in range(3):
            nums.append(i)
            time.sleep(1)
            print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums))
    
    def work2():
        """子进程要执行的代码"""
        print("in process2 pid=%d ,nums=%s" % (os.getpid(), nums))
    
    if __name__ == '__main__':
        p1 = Process(target=work1)
        p1.start()
        p1.join()

    p2 = Process(target=work2)
    p2.start()
### 进程-操作系统
`进程是操作系统资源分配和调度的基本单位`
`线程是cup调度和分配的基本单位`

进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统
进行调度的基本单位，线程是进程的一个实体，是CPU调度和分配的基本单位，它是比进程更小的
能独立运行的基本单位，线程自己基本不拥有系统资源，只拥有一点在运行中必不可少的资源
（程序计数器，一组寄存器和栈），线程可以与同属一个进程的其他线程共享进程的全部资源，
一个线程可以创建和撤销另一个线程，同一个进程中的多个线程之间可以并发执行


进程包含的内容有
- 地址空间
- 全局变量
- 打开的文件
- 子进程
- 信号量
- 账户信息

线程只拥有一点在运行中必不可少的资源（栈，程序计数器，寄存器，和状态）
线程可以共享进程的资源

### 进程间通信
用队列来实现进程间的通信，下面是一个 简单的例子 ，两个进程对队列进行读写
    
        from multiprocessing import Process, Queue
        import os, time, random
        
        def write(q):
            for value in ['A', 'B', 'C']:
                q.put(value)
        
        def read(q):
            while True:
                if not q.empty():
                    value = q.get(True)
                else:
                    break
        
        if __name__=='__main__':
            q = Queue()
            pw = Process(target=write, args=(q,))
            pr = Process(target=read, args=(q,))
            pw.start()    
            pw.join()
            pr.start()
            pr.join()
### 进程池pool
当我们不确定有多少子进程的时候，那么就需要进程池，指定每次运行进程的数目，其他进程排队等待
直到进程池中有空闲
    
    from multiprocessing import Pool
    import os, time, random
    
    def worker(msg):
        print(msg))
    
    po = Pool(3)  # 定义一个进程池，最大进程数3
    for i in range(0,10):
        # Pool().apply_async(要调用的目标,(传递给目标的参数元祖,))
        # 每次循环将会用空闲出来的子进程去调用目标
        po.apply_async(worker,(i,))
    po.close()  
    po.join()  

### 协程
协程是微线程，协程是完全由程序操控的，线程，进程都是由OS进行操作的，对于
阻塞状态和可运行状态的切换，线程上下文之间的切换，都是非常消耗资源的。
通过yeild关键字，可让协程暂停，这个过程完全是又用户控制的，其开销要远小于
又OS操作的线程阻塞,
经典的生产者 和消费者就是一个线程写消息，一个线程取消息，通过锁来控制
队列和等待， 改用协程后生产者，产生消息后直接跳转到消费者开始执行，
待消费者生产完毕后切换回生产者继续生产，
    
    import time
    def consumer():
        r = ''
        while True:
            n = yield r
            if not n:
                return
            print('[CONSUMER] Consuming %s...' % n)
            time.sleep(1)
            r = '200 OK'
    
    def produce(c):
        c.__next__()
        n = 0
        while n < 5:
            n = n + 1
            print('[PRODUCER] Producing %s...' % n)
            r = c.send(n)
            print('[PRODUCER] Consumer return: %s' % r)
        c.close()
    
    if __name__=='__main__':
        c = consumer()
        produce(c)

### gevent实现协程

    import time
    monkey.patch_all()
    def coroutine_work(coroutine_name):
        for i in range(10):
            print(coroutine_name, i)
            time.sleep(random.random())
    
    gevent.joinall([
        gevent.spawn(coroutine_work,'work1'),
        gevent.spawn(coroutine_work,'work2')
    ])




